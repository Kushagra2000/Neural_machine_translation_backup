{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine_translation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-4K2HI3_RBvxi7ln2M30dSS8qpHvCFTH",
      "authorship_tag": "ABX9TyOAe6TqIt0IJw4WUlR9EiOB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kushagra2000/Neural_machine_translation/blob/main/Machine_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "a_wTnIFR8vNu",
        "outputId": "129553b3-437b-4477-bc24-2baeb1cff143"
      },
      "source": [
        "#imports\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import unicodedata\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Activation,InputLayer,Embedding\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy,categorical_crossentropy\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# !pip install -q -U keras-tuner\n",
        "# import kerastuner as kt \n",
        "import IPython\n",
        "from keras.utils import to_categorical\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eacpqiV9DTc"
      },
      "source": [
        "#Upload the deu.txt file and put it in the Data Folder\n",
        "#!ls Data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pjnci4B5Aywh"
      },
      "source": [
        "#reading lines from the txt file\n",
        "num_examples=20000\n",
        "with open('drive/MyDrive/deu.txt','r',encoding='utf-8') as f:\n",
        "  lines=(f.readlines())\n",
        "lines=lines[:num_examples]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zDt6gkPfKhs"
      },
      "source": [
        "#Hyperparameters go here\n",
        "\n",
        "test_size=0.3\n",
        "m1_lr=0.001\n",
        "m2_lr=0.005\n",
        "m1_lstm_units=64\n",
        "m2_lstm_units=64\n",
        "m1_epochs=25\n",
        "m2_epochs=30\n",
        "m1_batch_size=128\n",
        "m2_batch_size=128\n",
        "m2_embedding_col=64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSnn6gGCBEy5"
      },
      "source": [
        "#removing the unnecessary data and obtaining sentence pairs \n",
        "def process_text(lines,translate_mode):\n",
        "  ''' \n",
        "  Takes a list of tab seperated\n",
        "  English and German sentences as input \n",
        "  and returns dataframe of processed\n",
        "  English and German sentence pairs\n",
        "  '''\n",
        "  proc_lines=[]\n",
        "  if translate_mode==False:\n",
        "    for line in lines:\n",
        "      line=line.strip() #to remove newlines at the end of a sentence\n",
        "      line=line.split(\"\\t\") #splitting by tabs\n",
        "      line=line[:-1]  #remove contributing information\n",
        "      \n",
        "      line[0]=''.join(c for c in unicodedata.normalize('NFD', line[0]) if unicodedata.category(c) != 'Mn')\n",
        "      line[0]=line[0].encode('utf8','ignore').decode('utf8')\n",
        "      line[0]=line[0].replace(u'\\u200b',' ')\n",
        "      line[0]=line[0].lower()\n",
        "      line[0]=line[0].replace('\\xa0', ' ')\n",
        "      line[0]=re.sub(r\"([.,?!;])\",r\" \\1 \",line[0])   #adding spaces before and after punctuation\n",
        "      line[0]=re.sub(r\"[0-9]\",\" \",line[0])  #removing numbers\n",
        "      line[0]=re.sub(r'[\"]',\" \",line[0])  #removing quotes\n",
        "      line[0]=re.sub(r\"[']\",\"\",line[0])\n",
        "      line[0]=re.sub(r\"[%-,]\",\" \",line[0])\n",
        "      line[0]=re.sub(r\"[:]\",\" \",line[0])\n",
        "      line[0]=re.sub(r'[\" \"]+',\" \",line[0])  #removing excess spaces\n",
        "      line[0]=line[0].strip() #removing spaces from the end of string\n",
        "      line[0]=\"<SOS> \"+line[0]+\" <EOS>\"\n",
        "\n",
        "      line[1]=''.join(c for c in unicodedata.normalize('NFD', line[1]) if unicodedata.category(c) != 'Mn')      \n",
        "      line[1]=line[1].replace(u'\\u200b',' ')\n",
        "      line[1]=line[1].replace('\\xa0', ' ')\n",
        "      line[1]=line[1].lower()\n",
        "      line[1]=re.sub(r\"([.,?!;])\",r\" \\1 \",line[1])\n",
        "      line[1]=re.sub(r\"[0-9]\",r\" \",line[1])\n",
        "      line[1]=re.sub(r'[\"]',\"\",line[1])\n",
        "      line[1]=re.sub(r'[—]',\"\",line[1])\n",
        "      line[1]=re.sub(r'[„]',\"\",line[1])\n",
        "      line[1]=re.sub(r'[“]',\"\",line[1])\n",
        "      line[1]=re.sub(r'[–]',\"\",line[1])\n",
        "      line[1]=re.sub(r'[‘‚]',\"\",line[1])\n",
        "      line[1]=re.sub(r\"[']\",\"\",line[1])\n",
        "      line[1]=re.sub(r\"[%()-,]\",\" \",line[1])\n",
        "      line[1]=re.sub(r\"[:]\",\" \",line[1])\n",
        "      line[1]=re.sub(r'[\" \"]+',\" \",line[1])\n",
        "      line[1]=line[1].strip()\n",
        "      line[1]=\"<SOS> \"+line[1]+\" <EOS>\"\n",
        "\n",
        "      proc_lines.append(line) \n",
        "    return pd.DataFrame.from_records(data=proc_lines,columns=['eng','ger'])\n",
        "  else:\n",
        "    lines=lines.strip()\n",
        "    lines=''.join(c for c in unicodedata.normalize('NFD', lines) if unicodedata.category(c) != 'Mn')\n",
        "    lines=lines.encode('utf8','ignore').decode('utf8')\n",
        "    lines=lines.replace(u'\\u200b',' ')\n",
        "    lines=lines.lower()\n",
        "    lines=lines.replace('\\xa0', ' ')\n",
        "    lines=re.sub(r\"([.,?!;])\",r\" \\1 \",lines)   #adding spaces before and after punctuation\n",
        "    lines=re.sub(r\"[0-9]\",\" \",lines)\n",
        "    lines=re.sub(r'[\"]',\" \",lines)\n",
        "    lines=re.sub(r\"[']\",\"\",lines)\n",
        "    lines=re.sub(r\"[%-,]\",\" \",lines)\n",
        "    lines=re.sub(r\"[:]\",\" \",lines)\n",
        "    lines=re.sub(r'[\" \"]+',\" \",lines)  #removing excess spaces\n",
        "    lines=lines.strip() #removing spaces from the end of string\n",
        "    lines=\"<SOS> \"+lines+\" <EOS>\"\n",
        "    return lines\n",
        "\n",
        "  \n",
        "     \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "vWgVr4xOBK33",
        "outputId": "a4e6327c-21f3-439d-962f-fca765d57c80"
      },
      "source": [
        "#reading in the dataset, sampling randomly, shuffling and removing duplicates \n",
        "df=process_text(lines,False)\n",
        "#df=df.sample(n=num_examples, random_state=1)\n",
        "df.drop_duplicates(subset=\"eng\",inplace=True)\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>ger</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;SOS&gt; youre decisive . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; du bist entschlossen . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;SOS&gt; can i hug you ? &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; darf ich dich umarmen ? &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;SOS&gt; im a good shot . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; ich bin ein guter schutze . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;SOS&gt; what wasnt easy ? &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; was war nicht einfach ? &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;SOS&gt; i must be blind . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; ich muss blind sein . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>&lt;SOS&gt; was tom here ? &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; war tom hier ? &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>&lt;SOS&gt; hes your friend . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; er ist dein freund . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>&lt;SOS&gt; dont be a baby . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; benimm dich nicht wie ein baby ! &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>&lt;SOS&gt; why do you lie ? &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; wieso lugst du ? &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>&lt;SOS&gt; i wanted to win . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; ich wollte gewinnen . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             eng                                           ger\n",
              "0   <SOS> youre decisive . <EOS>            <SOS> du bist entschlossen . <EOS>\n",
              "1    <SOS> can i hug you ? <EOS>           <SOS> darf ich dich umarmen ? <EOS>\n",
              "2   <SOS> im a good shot . <EOS>       <SOS> ich bin ein guter schutze . <EOS>\n",
              "3  <SOS> what wasnt easy ? <EOS>           <SOS> was war nicht einfach ? <EOS>\n",
              "4  <SOS> i must be blind . <EOS>             <SOS> ich muss blind sein . <EOS>\n",
              "5     <SOS> was tom here ? <EOS>                    <SOS> war tom hier ? <EOS>\n",
              "6  <SOS> hes your friend . <EOS>              <SOS> er ist dein freund . <EOS>\n",
              "7   <SOS> dont be a baby . <EOS>  <SOS> benimm dich nicht wie ein baby ! <EOS>\n",
              "8   <SOS> why do you lie ? <EOS>                  <SOS> wieso lugst du ? <EOS>\n",
              "9  <SOS> i wanted to win . <EOS>             <SOS> ich wollte gewinnen . <EOS>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "DNmFdtxhtnjz",
        "outputId": "7a535911-556d-430f-bbcc-4102f429e223"
      },
      "source": [
        "df.tail(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>ger</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14840</th>\n",
              "      <td>&lt;SOS&gt; ive got money . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; ich habe geld . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14841</th>\n",
              "      <td>&lt;SOS&gt; they liked tom . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; sie mochten tom . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14842</th>\n",
              "      <td>&lt;SOS&gt; im here again . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; ich bin wieder hier . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14843</th>\n",
              "      <td>&lt;SOS&gt; help me fix this . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; hilf mir das zu reparieren . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14844</th>\n",
              "      <td>&lt;SOS&gt; dont rub it in . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; streu nicht noch salz in die wunde ! &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14845</th>\n",
              "      <td>&lt;SOS&gt; this is a sign . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; das ist ein zeichen ! &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14846</th>\n",
              "      <td>&lt;SOS&gt; tom is devoted . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; tom ist hingebungsvoll . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14847</th>\n",
              "      <td>&lt;SOS&gt; its early . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; es ist fruh . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14848</th>\n",
              "      <td>&lt;SOS&gt; we went dancing . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; wir gingen tanzen . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14849</th>\n",
              "      <td>&lt;SOS&gt; that is his car . &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; das ist sein auto . &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  eng                                               ger\n",
              "14840     <SOS> ive got money . <EOS>                       <SOS> ich habe geld . <EOS>\n",
              "14841    <SOS> they liked tom . <EOS>                     <SOS> sie mochten tom . <EOS>\n",
              "14842     <SOS> im here again . <EOS>                 <SOS> ich bin wieder hier . <EOS>\n",
              "14843  <SOS> help me fix this . <EOS>          <SOS> hilf mir das zu reparieren . <EOS>\n",
              "14844    <SOS> dont rub it in . <EOS>  <SOS> streu nicht noch salz in die wunde ! <EOS>\n",
              "14845    <SOS> this is a sign . <EOS>                 <SOS> das ist ein zeichen ! <EOS>\n",
              "14846    <SOS> tom is devoted . <EOS>              <SOS> tom ist hingebungsvoll . <EOS>\n",
              "14847         <SOS> its early . <EOS>                         <SOS> es ist fruh . <EOS>\n",
              "14848   <SOS> we went dancing . <EOS>                   <SOS> wir gingen tanzen . <EOS>\n",
              "14849   <SOS> that is his car . <EOS>                   <SOS> das ist sein auto . <EOS>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zctawZ8xGF_R"
      },
      "source": [
        "class Vocab_builder():\n",
        "  '''\n",
        "  Builds vocabulary and \n",
        "  word to index and index to word dictionaries\n",
        "  from dataset\n",
        "  '''\n",
        "  def __init__(self,lang,series):\n",
        "    self.lang=lang\n",
        "    self.data=series\n",
        "  def tokenize(self,line):\n",
        "    return line.split(' ')\n",
        "  def build_vocab(self):\n",
        "    self.uniq_words=set()\n",
        "    \n",
        "    self.maxlen=0\n",
        "    count=3\n",
        "    self.num_list=[]\n",
        "    for index,line in self.data.items():\n",
        "      self.word_list=self.tokenize(line)\n",
        "      self.maxlen=max(len(self.word_list),self.maxlen)\n",
        "      for word in self.word_list:\n",
        "        if(word not in self.uniq_words and word!='<EOS>' and word!='<SOS>'):\n",
        "          self.uniq_words.add(word)\n",
        "          self.num_list.append(count)\n",
        "          count+=1\n",
        "      \n",
        "    self.vocab_list=['<PAD>','<SOS>','<EOS>']+sorted(list(self.uniq_words))\n",
        "    self.num_list=[0,1,2]+self.num_list\n",
        "    print(\"Built vocabulary having {} elements\".format(len(self.vocab_list)))\n",
        "    print(\"Largest sentence length (with tags):{}\".format(self.maxlen))\n",
        "    return dict(zip(self.vocab_list,self.num_list)),dict(zip(self.num_list,self.vocab_list))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JVuh6iKohIC"
      },
      "source": [
        "#Objects of Vocab_builder class\n",
        "eng=Vocab_builder('eng',df['eng'])\n",
        "ger=Vocab_builder('ger',df['ger'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uL4ZAsYizIsd",
        "outputId": "deca216f-79bf-4126-8bee-4f3e98c4fd68"
      },
      "source": [
        "#English word to index and index to word dictionaries\n",
        "eng_w2i,eng_i2w=eng.build_vocab()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Built vocabulary having 3655 elements\n",
            "Largest sentence length (with tags):9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsH4pLi3zOcS",
        "outputId": "913e64d6-c8cf-45bd-f424-287570180668"
      },
      "source": [
        "#checking for special characters in English dictionary\n",
        "for i in sorted (eng_w2i.keys())[:20] :  \n",
        "     print(i, end = \" \") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "! $ - . <EOS> <PAD> <SOS> ? a aah abandon abandoned abated abhor able aboard about abroad absent absurd "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWE4mEkcMF2T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81cf4bb4-57e5-418e-c8ee-fab2969bb1e4"
      },
      "source": [
        "#German word to index and index to word dictionaries\n",
        "ger_w2i,ger_i2w=ger.build_vocab()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Built vocabulary having 4892 elements\n",
            "Largest sentence length (with tags):13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDAzP_ePoJK0",
        "outputId": "1dbc771e-6825-4b46-c23c-86cd64271cb4"
      },
      "source": [
        "#checking if the index dictionaries are correct\n",
        "'geh'==ger_i2w[ger_w2i['geh']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tylnxt3Xoqj3",
        "outputId": "bde4dc3c-a25d-4bfc-bdc0-167ead0d9562"
      },
      "source": [
        "'go'==eng_i2w[eng_w2i['go']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rglyUxdDxD3Z",
        "outputId": "044908a0-2629-4623-f2d0-96b44f5181d9"
      },
      "source": [
        "#checking for special characters in German dictionary\n",
        "for i in sorted (ger_w2i.keys())[:20] :  \n",
        "     print(i, end = \" \") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "! $ - . <EOS> <PAD> <SOS> ? ab abbiegen abend abendbrot abendessen abenteuer aber abgefahren abgekommen abgelaufen abgelehnt abgelenkt "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HctDyjqmxKuX"
      },
      "source": [
        "def sent_to_ind(sentence,lang):\n",
        "  '''\n",
        "  Tokenizes a string and\n",
        "  converts it to an np array of \n",
        "  indices and pads the \n",
        "  array according to max sentence length\n",
        "  '''\n",
        "  ind_list=[]\n",
        "  if lang=='eng':\n",
        "    tokens=eng.tokenize(sentence)\n",
        "    for token in tokens:\n",
        "      ind_list.append(eng_w2i[token])\n",
        "    while len(ind_list)<max(ger.maxlen,eng.maxlen):\n",
        "      ind_list.append(0)\n",
        "  else:\n",
        "    tokens=ger.tokenize(sentence)\n",
        "    for token in tokens:\n",
        "      ind_list.append(ger_w2i[token])\n",
        "    while len(ind_list)<max(ger.maxlen,eng.maxlen):\n",
        "      ind_list.append(0)\n",
        "    \n",
        "  return np.array(ind_list)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix5EpSK3eQod",
        "outputId": "5656a179-ff82-4320-cd2a-7a31ed80e424"
      },
      "source": [
        "#Checking correctness of sentence to index conversion\n",
        "test_lis=sent_to_ind('<SOS> tom wird bald hier sein . was heißt bald ? <EOS>','ger')\n",
        "\n",
        "print(len(test_lis))\n",
        "print(test_lis)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13\n",
            "[   1 4003 4686  309 1988 3604    6 4568 1946  309    7    2    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJfhMnYBhXb8",
        "outputId": "8ff9439f-20e6-4bba-8486-5183a195d494"
      },
      "source": [
        "test_lis=sent_to_ind(\"<SOS> tom will be here soon . how soon ? <EOS>\",'eng')\n",
        "print(len(test_lis))\n",
        "print(test_lis)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13\n",
            "[   1 3269 3557  262 1477 2927    6 1551 2927    7    2    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VENEOHriC99"
      },
      "source": [
        "#splitting the data into training,testing and validation sets\n",
        "\n",
        "train_x,test_x,train_y,test_y=train_test_split(df['eng'],df['ger'],test_size=0.1,random_state=42)\n",
        "train_x,val_x,train_y,val_y=train_test_split(train_x,train_y,test_size=0.23,random_state=42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NetMWl-AtVvi"
      },
      "source": [
        "def sent_to_np(series,lang,translate_mode):\n",
        "  '''\n",
        "  Converts a dataframe column to \n",
        "  a unsqueezed np array of indexes\n",
        "  with padding for feeding into NN\n",
        "  '''\n",
        "  ret_list=[]\n",
        "  if translate_mode==False :\n",
        "    if lang=='eng':\n",
        "      for index,val in series.items():\n",
        "        ret_list.append(sent_to_ind(val,'eng'))\n",
        "    else:\n",
        "      for index,val in series.items():\n",
        "        ret_list.append(sent_to_ind(val,'ger'))\n",
        "    \n",
        "    ret_list=np.array(ret_list)\n",
        "    return np.expand_dims(ret_list,axis=2)\n",
        "  else:\n",
        "    ans=sent_to_ind(series,'eng')\n",
        "    ans=np.expand_dims(ans,axis=0)\n",
        "    ans=np.expand_dims(ans,axis=2)\n",
        "    return ans\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdCHrrTaSqww"
      },
      "source": [
        "train_x=sent_to_np(train_x,'eng',False)\n",
        "train_y=sent_to_np(train_y,'ger',False)\n",
        "test_x=sent_to_np(test_x,'eng',False)\n",
        "test_y=sent_to_np(test_y,'ger',False)\n",
        "val_x=sent_to_np(val_x,'eng',False)\n",
        "val_y=sent_to_np(val_y,'ger',False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEbhTzocTrYu"
      },
      "source": [
        "#loading training,testing and validation data\n",
        "\n",
        "# train_x=np.load(\"drive/MyDrive/data/training/train_x.npy\")\n",
        "# train_y=np.load(\"drive/MyDrive/data/training/train_y.npy\")\n",
        "\n",
        "# test_x=np.load(\"drive/MyDrive/data/testing/test_x.npy\")\n",
        "# test_y=np.load(\"drive/MyDrive/data/testing/test_y.npy\")\n",
        "\n",
        "# val_x=np.load(\"drive/MyDrive/data/validation/val_x.npy\")\n",
        "# val_y=np.load(\"drive/MyDrive/data/validation/val_y.npy\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLHAZ_vw7un7",
        "outputId": "ce88a74e-af60-4d17-a91c-c23033a2c987"
      },
      "source": [
        "train_y=to_categorical(train_y,num_classes=len(ger.vocab_list))\r\n",
        "test_y=to_categorical(test_y,num_classes=len(ger.vocab_list))\r\n",
        "val_y=to_categorical(val_y,num_classes=len(ger.vocab_list))\r\n",
        "print(train_y.shape)\r\n",
        "print(test_y.shape)\r\n",
        "print(val_y.shape)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10291, 13, 4892)\n",
            "(1485, 13, 4892)\n",
            "(3074, 13, 4892)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDpCjhQZur_O",
        "outputId": "6ea5bd11-f8d5-43a9-d898-16dccd03a723"
      },
      "source": [
        "# [batch,timesteps,feature]\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10291, 13, 1)\n",
            "(10291, 13, 4892)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Frd_j1wuxz5",
        "outputId": "900f0cf3-297d-4741-e540-dbd70450b33d"
      },
      "source": [
        "print(test_x.shape)\n",
        "print(test_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1485, 13, 1)\n",
            "(1485, 13, 4892)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1dFoeFhuzjt",
        "outputId": "40224b81-c09d-402d-ca10-12022f0154ae"
      },
      "source": [
        "print(val_x.shape)\n",
        "print(val_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3074, 13, 1)\n",
            "(3074, 13, 4892)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Zt6VKybF7WK"
      },
      "source": [
        "def translate(sentence,mod,embedded):\n",
        "  '''\n",
        "  Function for translating given English sentence\n",
        "  to German using model predictions\n",
        "  '''\n",
        "  ans=\"\"\n",
        "  preproc_sent=process_text(sentence,True)\n",
        "  #print(preproc_sent)\n",
        "  model_inp=sent_to_np(preproc_sent,'eng',True)\n",
        "  if (embedded):\n",
        "    model_inp=np.squeeze(model_inp,axis=2)\n",
        "  #print(model_inp)\n",
        "  pred=mod.predict(model_inp)\n",
        "  #print(pred)\n",
        "  for i in pred[0]:\n",
        "    ind=np.argmax(i)\n",
        "    #print(ind)\n",
        "    #print(\"MAX:\",i[ind])\n",
        "    #print(i[24])\n",
        "    if(ger_i2w[ind]=='<SOS>' or ger_i2w[ind]=='<EOS>' or ger_i2w[ind]=='<PAD>'):\n",
        "        continue\n",
        "    ans+=ger_i2w[ind]\n",
        "    ans+=\" \"\n",
        "  return ans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_cqENbVFpVI"
      },
      "source": [
        "#training starts here ----------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jBADUl-Buhn",
        "outputId": "f4ebd452-344c-41c9-8e3f-da871a974f68"
      },
      "source": [
        "\n",
        "#Removing singleton axis  3rd axis\n",
        "#for embedding layer\n",
        "t_x=np.squeeze(train_x,axis=2)\n",
        "v_x=np.squeeze(val_x,axis=2)\n",
        "te_x=np.squeeze(test_x,axis=2)\n",
        "print(t_x.shape)\n",
        "print(v_x.shape)\n",
        "print(te_x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10291, 13)\n",
            "(3074, 13)\n",
            "(1485, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEFKmQmibP_y"
      },
      "source": [
        "def f1_score(y_true,y_pred):\n",
        "  p=tf.keras.metrics.Precision()\n",
        "  r=tf.keras.metrics.Recall()\n",
        "  p.update_state(y_true,y_pred)\n",
        "  r.update_state(y_true,y_pred)\n",
        "  return (2*p.result()*r.result())/(p.result()+r.result());\n",
        "def leaky_relu(x):\n",
        "    return tf.nn.leaky_relu(x, alpha=0.03)\n",
        "\n",
        "\n",
        "def base_LSTM_model_HP_TUNING(hp):\n",
        "  '''\n",
        "  Simple LSTM model for hyperparameter tuning\n",
        "  '''\n",
        "  m1_lstm_units=hp.Int('units',min_value=32,max_value=128,step=32)\n",
        "  m1_lr=hp.Choice('learning_rate', values = [0.001,0.003,0.005,0.008,0.01,0.05]) \n",
        "  lstm=LSTM(m1_lstm_units,return_sequences=True,activation='tanh')  #LSTM layer with output being hiddent state at time t\n",
        "  layer_at_t=TimeDistributed(Dense(len(ger.vocab_list),activation='softmax')) #Dense layer acting on hidden output at each step to generate predictions\n",
        "  model=tf.keras.Sequential()\n",
        "  model.add(InputLayer(train_x.shape[1:]))\n",
        "  model.add(lstm)\n",
        "  model.add(layer_at_t)\n",
        "\n",
        "  model.compile(loss=sparse_categorical_crossentropy,optimizer=Adam(m1_lr),metrics=['accuracy','MeanSquaredError',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQohAY2OPyV8"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "def embedding_LSTM_HP_TUNING(hp):\n",
        "  '''\n",
        "  LSTM model with embedding layer for hyperparameter tuning\n",
        "  '''\n",
        "  m2_lstm_units=hp.Int('units',min_value=32,max_value=128,step=32)\n",
        "  m2_lr=hp.Choice('learning_rate', values = [0.001,0.003,0.005,0.008,0.01,0.05,0.08])\n",
        "  embedding_col=hp.Int('output_dim',min_value=32,max_value=160,step=32)\n",
        "  lstm=LSTM(m2_lstm_units,return_sequences=True,activation='tanh')\n",
        "  print(t_x.shape[1])\n",
        "  embed=Embedding(len(ger.vocab_list),embedding_col,input_length=t_x.shape[1])\n",
        "  layer_at_t=TimeDistributed(Dense(len(ger.vocab_list),activation=\"softmax\"))\n",
        "  model=tf.keras.Sequential()\n",
        "  model.add(embed)\n",
        "  model.add(lstm)\n",
        "  model.add(layer_at_t)\n",
        "\n",
        "  model.compile(loss=sparse_categorical_crossentropy,optimizer=Adam(m2_lr),metrics=['accuracy','MeanSquaredError',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
        "  return model\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxxlHHvjIAjf"
      },
      "source": [
        "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
        "  def on_train_end(*args, **kwargs):\n",
        "    IPython.display.clear_output(wait = True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6eCU8-iy7Ii"
      },
      "source": [
        "#Hyperparameter tuning starts here\n",
        "#Hyperparameter tuning of base model\n",
        "# tuner = kt.BayesianOptimization(base_LSTM_model_HP_TUNING,\n",
        "#                      objective = 'val_accuracy', \n",
        "#                      num_initial_points=50,\n",
        "#                      max_trials=15,\n",
        "#                      directory='./',\n",
        "#                      project_name='base_LSTM')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_jHXV22JtT1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9356eca9-f117-470e-e2a1-bc4c6b8ec9f0"
      },
      "source": [
        "tuner.search(train_x,train_y, epochs = 25, validation_data = (val_x, val_y), callbacks = [ClearTrainingOutput()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 16 Complete [00h 02m 53s]\n",
            "val_accuracy: 0.7552497386932373\n",
            "\n",
            "Best val_accuracy So Far: 0.765637218952179\n",
            "Total elapsed time: 00h 47m 45s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRHXC9iqgFgA"
      },
      "source": [
        "best_hps1 = tuner.get_best_hyperparameters(num_trials = 1)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA7iXB2uieqC",
        "outputId": "c5b350f3-0052-4ec6-9b71-ee66e7fec116"
      },
      "source": [
        "best_hps1.get('units')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaZPnvb3igA4",
        "outputId": "edf45185-7648-4e5f-e907-3f4a03fc7f3c"
      },
      "source": [
        "best_hps1.get('learning_rate')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVv7aXRFioJy",
        "outputId": "7167fc26-6179-4060-cd70-c852a4882579"
      },
      "source": [
        "tuner2 = kt.BayesianOptimization(embedding_LSTM_HP_TUNING,\n",
        "                     objective = 'val_accuracy', \n",
        "                     num_initial_points=50,\n",
        "                     max_trials=30,\n",
        "                     directory='./',\n",
        "                     project_name='embedding')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "351_XxE0wjvx",
        "outputId": "d721d465-7a63-4c7b-c307-5be934665b9f"
      },
      "source": [
        "tuner2.search(t_x,train_y, epochs = 30, validation_data = (v_x, val_y), callbacks = [ClearTrainingOutput()])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 30 Complete [00h 07m 08s]\n",
            "val_accuracy: 0.8056359887123108\n",
            "\n",
            "Best val_accuracy So Far: 0.8067874908447266\n",
            "Total elapsed time: 03h 46m 53s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuFGzxbtwkzH"
      },
      "source": [
        "best_hps2 = tuner2.get_best_hyperparameters(num_trials = 1)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3PWz0b9wkwx",
        "outputId": "4e28e262-02b5-46d4-cbe7-b62db5543bda"
      },
      "source": [
        "best_hps2.get('units')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdrijzI-wktw",
        "outputId": "27d76356-c513-49f8-f3d8-bae31c21bd26"
      },
      "source": [
        "best_hps2.get('learning_rate')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAwDCBOOxPbb",
        "outputId": "c50c6b2d-9153-4c12-f565-8cabdc9f7c32"
      },
      "source": [
        "best_hps2.get('output_dim')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE19whgFWcVE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDRqYzYqv6uX"
      },
      "source": [
        "#Making base model using best hyperparameters\n",
        "def base_LSTM_model(m1_lstm_units,m1_lr):\n",
        "  '''\n",
        "  Simple LSTM model\n",
        "  '''\n",
        "  lstm=LSTM(m1_lstm_units,return_sequences=True,activation='tanh')  #LSTM layer with output being hiddent state at time t\n",
        "  layer_at_t=TimeDistributed(Dense(len(ger.vocab_list),activation='softmax')) #Dense layer acting on hidden output at each step to generate predictions\n",
        "  model=tf.keras.Sequential()\n",
        "  model.add(InputLayer(train_x.shape[1:]))\n",
        "  model.add(lstm)\n",
        "  model.add(layer_at_t)\n",
        "\n",
        "  model.compile(loss=categorical_crossentropy,optimizer=Adam(m1_lr),metrics=['accuracy','MeanSquaredError',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFvJdTxXw6It"
      },
      "source": [
        "#Making embedding model using hyperparameters\n",
        "def embedding_LSTM(m2_lstm_units,m2_lr,embedding_col):\n",
        "  '''\n",
        "  LSTM model with embedding layer\n",
        "  '''\n",
        "  lstm=LSTM(m2_lstm_units,return_sequences=True,activation='tanh')\n",
        "  print(t_x.shape[1])\n",
        "  embed=Embedding(len(ger.vocab_list),embedding_col,input_length=t_x.shape[1])\n",
        "  layer_at_t=TimeDistributed(Dense(len(ger.vocab_list),activation=\"softmax\"))\n",
        "  model=tf.keras.Sequential()\n",
        "  model.add(embed)\n",
        "  model.add(lstm)\n",
        "  model.add(layer_at_t)\n",
        "\n",
        "  model.compile(loss=categorical_crossentropy,optimizer=Adam(m2_lr),metrics=['accuracy','MeanSquaredError',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWOrrfsRNOcT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7441b04a-19ac-4115-b6b5-c4f190c1d732"
      },
      "source": [
        "base_model=base_LSTM_model(128,0.001)\n",
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_6 (LSTM)                (None, 13, 128)           66560     \n",
            "_________________________________________________________________\n",
            "time_distributed_6 (TimeDist (None, 13, 4892)          631068    \n",
            "=================================================================\n",
            "Total params: 697,628\n",
            "Trainable params: 697,628\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bzsf600cPN9w",
        "outputId": "38b3f890-455e-4cc4-f33c-6a5cb5d958ad"
      },
      "source": [
        "#training the base model\n",
        "\n",
        "base_model.fit(train_x,train_y,m1_batch_size,m1_epochs,validation_data=(val_x,val_y))\n",
        "#base_model.save(\"Less_trained_base.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10291 samples, validate on 3074 samples\n",
            "Epoch 1/25\n",
            "10291/10291 [==============================] - 5s 527us/sample - loss: 4.4040 - acc: 0.4942 - mean_squared_error: 1.4624e-04 - precision_7: 0.8602 - recall_6: 0.2758 - val_loss: 2.7209 - val_acc: 0.5539 - val_mean_squared_error: 1.0406e-04 - val_precision_7: 0.9218 - val_recall_6: 0.4873\n",
            "Epoch 2/25\n",
            "10291/10291 [==============================] - 5s 449us/sample - loss: 2.6246 - acc: 0.6319 - mean_squared_error: 1.0174e-04 - precision_7: 0.9256 - recall_6: 0.4815 - val_loss: 2.5904 - val_acc: 0.6359 - val_mean_squared_error: 1.0024e-04 - val_precision_7: 0.9224 - val_recall_6: 0.4870\n",
            "Epoch 3/25\n",
            "10291/10291 [==============================] - 5s 447us/sample - loss: 2.4948 - acc: 0.6522 - mean_squared_error: 1.0012e-04 - precision_7: 0.9298 - recall_6: 0.4784 - val_loss: 2.4443 - val_acc: 0.6540 - val_mean_squared_error: 9.9470e-05 - val_precision_7: 0.9225 - val_recall_6: 0.4871\n",
            "Epoch 4/25\n",
            "10291/10291 [==============================] - 5s 452us/sample - loss: 2.2647 - acc: 0.6551 - mean_squared_error: 9.8784e-05 - precision_7: 0.9268 - recall_6: 0.4818 - val_loss: 2.1417 - val_acc: 0.6616 - val_mean_squared_error: 9.5921e-05 - val_precision_7: 0.9200 - val_recall_6: 0.4873\n",
            "Epoch 5/25\n",
            "10291/10291 [==============================] - 5s 450us/sample - loss: 1.9690 - acc: 0.6632 - mean_squared_error: 8.8187e-05 - precision_7: 0.9296 - recall_6: 0.5241 - val_loss: 1.9557 - val_acc: 0.6626 - val_mean_squared_error: 8.3219e-05 - val_precision_7: 0.9271 - val_recall_6: 0.5671\n",
            "Epoch 6/25\n",
            "10291/10291 [==============================] - 5s 452us/sample - loss: 1.8798 - acc: 0.6618 - mean_squared_error: 8.2921e-05 - precision_7: 0.9281 - recall_6: 0.5673 - val_loss: 1.9243 - val_acc: 0.6640 - val_mean_squared_error: 8.2241e-05 - val_precision_7: 0.9221 - val_recall_6: 0.5740\n",
            "Epoch 7/25\n",
            "10291/10291 [==============================] - 5s 450us/sample - loss: 1.8528 - acc: 0.6636 - mean_squared_error: 8.2353e-05 - precision_7: 0.9200 - recall_6: 0.5746 - val_loss: 1.9073 - val_acc: 0.6633 - val_mean_squared_error: 8.1784e-05 - val_precision_7: 0.9315 - val_recall_6: 0.5686\n",
            "Epoch 8/25\n",
            "10291/10291 [==============================] - 5s 451us/sample - loss: 1.8337 - acc: 0.6651 - mean_squared_error: 8.1887e-05 - precision_7: 0.9198 - recall_6: 0.5789 - val_loss: 1.8938 - val_acc: 0.6639 - val_mean_squared_error: 8.1342e-05 - val_precision_7: 0.9215 - val_recall_6: 0.5791\n",
            "Epoch 9/25\n",
            "10291/10291 [==============================] - 5s 445us/sample - loss: 1.8174 - acc: 0.6692 - mean_squared_error: 8.1509e-05 - precision_7: 0.9189 - recall_6: 0.5815 - val_loss: 1.8848 - val_acc: 0.6635 - val_mean_squared_error: 8.1134e-05 - val_precision_7: 0.9245 - val_recall_6: 0.5764\n",
            "Epoch 10/25\n",
            "10291/10291 [==============================] - 5s 445us/sample - loss: 1.8008 - acc: 0.6792 - mean_squared_error: 8.1103e-05 - precision_7: 0.9167 - recall_6: 0.5850 - val_loss: 1.8747 - val_acc: 0.6854 - val_mean_squared_error: 8.0760e-05 - val_precision_7: 0.9275 - val_recall_6: 0.5739\n",
            "Epoch 11/25\n",
            "10291/10291 [==============================] - 5s 446us/sample - loss: 1.7818 - acc: 0.6850 - mean_squared_error: 8.0535e-05 - precision_7: 0.9131 - recall_6: 0.5880 - val_loss: 1.8580 - val_acc: 0.6876 - val_mean_squared_error: 8.0037e-05 - val_precision_7: 0.9019 - val_recall_6: 0.5964\n",
            "Epoch 12/25\n",
            "10291/10291 [==============================] - 5s 447us/sample - loss: 1.7634 - acc: 0.6870 - mean_squared_error: 8.0027e-05 - precision_7: 0.9113 - recall_6: 0.5890 - val_loss: 1.8436 - val_acc: 0.6888 - val_mean_squared_error: 7.9498e-05 - val_precision_7: 0.9002 - val_recall_6: 0.5971\n",
            "Epoch 13/25\n",
            "10291/10291 [==============================] - 5s 446us/sample - loss: 1.7424 - acc: 0.6890 - mean_squared_error: 7.9367e-05 - precision_7: 0.9099 - recall_6: 0.5914 - val_loss: 1.8328 - val_acc: 0.6891 - val_mean_squared_error: 7.8929e-05 - val_precision_7: 0.9125 - val_recall_6: 0.5885\n",
            "Epoch 14/25\n",
            "10291/10291 [==============================] - 5s 446us/sample - loss: 1.7252 - acc: 0.6910 - mean_squared_error: 7.8929e-05 - precision_7: 0.9118 - recall_6: 0.5913 - val_loss: 1.8177 - val_acc: 0.6907 - val_mean_squared_error: 7.8505e-05 - val_precision_7: 0.9214 - val_recall_6: 0.5817\n",
            "Epoch 15/25\n",
            "10291/10291 [==============================] - 5s 443us/sample - loss: 1.7086 - acc: 0.6935 - mean_squared_error: 7.8492e-05 - precision_7: 0.9119 - recall_6: 0.5918 - val_loss: 1.8097 - val_acc: 0.6939 - val_mean_squared_error: 7.8435e-05 - val_precision_7: 0.8962 - val_recall_6: 0.6022\n",
            "Epoch 16/25\n",
            "10291/10291 [==============================] - 5s 448us/sample - loss: 1.6937 - acc: 0.6950 - mean_squared_error: 7.8180e-05 - precision_7: 0.9070 - recall_6: 0.5955 - val_loss: 1.7972 - val_acc: 0.6962 - val_mean_squared_error: 7.7946e-05 - val_precision_7: 0.9155 - val_recall_6: 0.5868\n",
            "Epoch 17/25\n",
            "10291/10291 [==============================] - 5s 444us/sample - loss: 1.6800 - acc: 0.6967 - mean_squared_error: 7.7881e-05 - precision_7: 0.9108 - recall_6: 0.5942 - val_loss: 1.7888 - val_acc: 0.6965 - val_mean_squared_error: 7.7759e-05 - val_precision_7: 0.9338 - val_recall_6: 0.5726\n",
            "Epoch 18/25\n",
            "10291/10291 [==============================] - 5s 447us/sample - loss: 1.6681 - acc: 0.6978 - mean_squared_error: 7.7700e-05 - precision_7: 0.9141 - recall_6: 0.5925 - val_loss: 1.7812 - val_acc: 0.6993 - val_mean_squared_error: 7.7459e-05 - val_precision_7: 0.8950 - val_recall_6: 0.6063\n",
            "Epoch 19/25\n",
            "10291/10291 [==============================] - 5s 444us/sample - loss: 1.6574 - acc: 0.6986 - mean_squared_error: 7.7534e-05 - precision_7: 0.9107 - recall_6: 0.5960 - val_loss: 1.7770 - val_acc: 0.6993 - val_mean_squared_error: 7.7427e-05 - val_precision_7: 0.8995 - val_recall_6: 0.6014\n",
            "Epoch 20/25\n",
            "10291/10291 [==============================] - 5s 443us/sample - loss: 1.6484 - acc: 0.6992 - mean_squared_error: 7.7411e-05 - precision_7: 0.9071 - recall_6: 0.5994 - val_loss: 1.7737 - val_acc: 0.6971 - val_mean_squared_error: 7.7396e-05 - val_precision_7: 0.9000 - val_recall_6: 0.6014\n",
            "Epoch 21/25\n",
            "10291/10291 [==============================] - 5s 443us/sample - loss: 1.6378 - acc: 0.7000 - mean_squared_error: 7.7232e-05 - precision_7: 0.9069 - recall_6: 0.5995 - val_loss: 1.7654 - val_acc: 0.6991 - val_mean_squared_error: 7.7194e-05 - val_precision_7: 0.9035 - val_recall_6: 0.6004\n",
            "Epoch 22/25\n",
            "10291/10291 [==============================] - 5s 446us/sample - loss: 1.6280 - acc: 0.7010 - mean_squared_error: 7.7102e-05 - precision_7: 0.9051 - recall_6: 0.6030 - val_loss: 1.7644 - val_acc: 0.6994 - val_mean_squared_error: 7.7433e-05 - val_precision_7: 0.9163 - val_recall_6: 0.5859\n",
            "Epoch 23/25\n",
            "10291/10291 [==============================] - 5s 445us/sample - loss: 1.6202 - acc: 0.7011 - mean_squared_error: 7.7088e-05 - precision_7: 0.9051 - recall_6: 0.6019 - val_loss: 1.7582 - val_acc: 0.7003 - val_mean_squared_error: 7.7037e-05 - val_precision_7: 0.9151 - val_recall_6: 0.6016\n",
            "Epoch 24/25\n",
            "10291/10291 [==============================] - 5s 441us/sample - loss: 1.6113 - acc: 0.7022 - mean_squared_error: 7.6917e-05 - precision_7: 0.9046 - recall_6: 0.6055 - val_loss: 1.7559 - val_acc: 0.7004 - val_mean_squared_error: 7.7177e-05 - val_precision_7: 0.9123 - val_recall_6: 0.5896\n",
            "Epoch 25/25\n",
            "10291/10291 [==============================] - 5s 446us/sample - loss: 1.6045 - acc: 0.7021 - mean_squared_error: 7.6867e-05 - precision_7: 0.9026 - recall_6: 0.6087 - val_loss: 1.7498 - val_acc: 0.7025 - val_mean_squared_error: 7.6796e-05 - val_precision_7: 0.8858 - val_recall_6: 0.6167\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4660f234a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9vjPm2GCYKh"
      },
      "source": [
        "# base_model=tf.keras.models.load_model(\"drive/MyDrive/model/Less_trained_base.h5\")\n",
        "# base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nDxB8O0Dr33",
        "outputId": "b27e8b72-27a8-4800-bab2-340733b745d8"
      },
      "source": [
        "#Evaluating LSTM model on unseen data\n",
        "\n",
        "l,acc,mse,p,r=base_model.evaluate(test_x,test_y)\n",
        "print(\"Base model loss for testing set:{}\".format(l))\n",
        "print(\"Base model accuracy for testing set:{}\".format(acc))\n",
        "print(\"Base model precision for testing set:{}\".format(p))\n",
        "print(\"Base model recall for testing set:{}\".format(r))\n",
        "print(\"Base model f1_score for testing set:{}\".format((2*p*r)/(p+r)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1485/1485 [==============================] - 1s 400us/sample - loss: 1.7264 - acc: 0.7080 - mean_squared_error: 7.6027e-05 - precision_7: 0.8947 - recall_6: 0.6224\n",
            "Base model loss for testing set:1.7263565836530743\n",
            "Base model accuracy for testing set:0.7080031037330627\n",
            "Base model precision for testing set:0.8947054743766785\n",
            "Base model recall for testing set:0.6223776340484619\n",
            "Base model f1_score for testing set:0.73409907650077\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-V7nQnNrM6ck",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2be4360f-6157-4e3c-8c20-0c2bf7aa7bff"
      },
      "source": [
        "#Sample translation by base LSTM model\n",
        "translate(\"work here\",base_model,False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'tom ist ! ! '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eB5CvJLV5LzC",
        "outputId": "1e0ce29e-b71d-45a9-e7e5-50253e1d4518"
      },
      "source": [
        "embeded_model=embedding_LSTM(96,0.01,128)\n",
        "embeded_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 13, 64)            313088    \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 13, 96)            61824     \n",
            "_________________________________________________________________\n",
            "time_distributed_9 (TimeDist (None, 13, 4892)          474524    \n",
            "=================================================================\n",
            "Total params: 849,436\n",
            "Trainable params: 849,436\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUWKsmwb5bZB",
        "outputId": "7cb3d48c-a9ec-428e-c843-8f13d7e1f367"
      },
      "source": [
        "#training embedding model\n",
        "embeded_model.fit(t_x,train_y,batch_size=128,epochs=15,validation_data=(v_x,val_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10291 samples, validate on 3074 samples\n",
            "Epoch 1/15\n",
            "10291/10291 [==============================] - 6s 582us/sample - loss: 3.2519 - acc: 0.5582 - mean_squared_error: 1.2217e-04 - precision_10: 0.7860 - recall_9: 0.4688 - val_loss: 2.2596 - val_acc: 0.6592 - val_mean_squared_error: 8.3884e-05 - val_precision_10: 0.9566 - val_recall_9: 0.5594\n",
            "Epoch 2/15\n",
            "10291/10291 [==============================] - 5s 472us/sample - loss: 2.0892 - acc: 0.6905 - mean_squared_error: 7.9235e-05 - precision_10: 0.9608 - recall_9: 0.5665 - val_loss: 1.9971 - val_acc: 0.7094 - val_mean_squared_error: 7.5222e-05 - val_precision_10: 0.9412 - val_recall_9: 0.5969\n",
            "Epoch 3/15\n",
            "10291/10291 [==============================] - 5s 477us/sample - loss: 1.6992 - acc: 0.7253 - mean_squared_error: 6.9341e-05 - precision_10: 0.9387 - recall_9: 0.6597 - val_loss: 1.6192 - val_acc: 0.7363 - val_mean_squared_error: 6.7545e-05 - val_precision_10: 0.9228 - val_recall_9: 0.6767\n",
            "Epoch 4/15\n",
            "10291/10291 [==============================] - 5s 472us/sample - loss: 1.4553 - acc: 0.7560 - mean_squared_error: 6.2107e-05 - precision_10: 0.9337 - recall_9: 0.7077 - val_loss: 1.5081 - val_acc: 0.7568 - val_mean_squared_error: 6.3325e-05 - val_precision_10: 0.9164 - val_recall_9: 0.7095\n",
            "Epoch 5/15\n",
            "10291/10291 [==============================] - 5s 470us/sample - loss: 1.3077 - acc: 0.7754 - mean_squared_error: 5.7501e-05 - precision_10: 0.9353 - recall_9: 0.7314 - val_loss: 1.4334 - val_acc: 0.7700 - val_mean_squared_error: 6.0513e-05 - val_precision_10: 0.9172 - val_recall_9: 0.7238\n",
            "Epoch 6/15\n",
            "10291/10291 [==============================] - 5s 471us/sample - loss: 1.1868 - acc: 0.7925 - mean_squared_error: 5.3996e-05 - precision_10: 0.9376 - recall_9: 0.7481 - val_loss: 1.3838 - val_acc: 0.7767 - val_mean_squared_error: 5.9778e-05 - val_precision_10: 0.9094 - val_recall_9: 0.7349\n",
            "Epoch 7/15\n",
            "10291/10291 [==============================] - 5s 470us/sample - loss: 1.0839 - acc: 0.8067 - mean_squared_error: 5.1202e-05 - precision_10: 0.9387 - recall_9: 0.7617 - val_loss: 1.3328 - val_acc: 0.7859 - val_mean_squared_error: 5.7832e-05 - val_precision_10: 0.9111 - val_recall_9: 0.7428\n",
            "Epoch 8/15\n",
            "10291/10291 [==============================] - 5s 475us/sample - loss: 0.9942 - acc: 0.8169 - mean_squared_error: 4.9087e-05 - precision_10: 0.9397 - recall_9: 0.7707 - val_loss: 1.3032 - val_acc: 0.7913 - val_mean_squared_error: 5.7173e-05 - val_precision_10: 0.9095 - val_recall_9: 0.7470\n",
            "Epoch 9/15\n",
            "10291/10291 [==============================] - 5s 475us/sample - loss: 0.9111 - acc: 0.8278 - mean_squared_error: 4.6796e-05 - precision_10: 0.9423 - recall_9: 0.7824 - val_loss: 1.2795 - val_acc: 0.7962 - val_mean_squared_error: 5.6373e-05 - val_precision_10: 0.9065 - val_recall_9: 0.7544\n",
            "Epoch 10/15\n",
            "10291/10291 [==============================] - 5s 475us/sample - loss: 0.8380 - acc: 0.8366 - mean_squared_error: 4.4991e-05 - precision_10: 0.9432 - recall_9: 0.7898 - val_loss: 1.2581 - val_acc: 0.8027 - val_mean_squared_error: 5.5393e-05 - val_precision_10: 0.9066 - val_recall_9: 0.7625\n",
            "Epoch 11/15\n",
            "10291/10291 [==============================] - 5s 477us/sample - loss: 0.7716 - acc: 0.8443 - mean_squared_error: 4.3229e-05 - precision_10: 0.9450 - recall_9: 0.7981 - val_loss: 1.2481 - val_acc: 0.8037 - val_mean_squared_error: 5.5615e-05 - val_precision_10: 0.9050 - val_recall_9: 0.7612\n",
            "Epoch 12/15\n",
            "10291/10291 [==============================] - 5s 473us/sample - loss: 0.7099 - acc: 0.8529 - mean_squared_error: 4.1459e-05 - precision_10: 0.9462 - recall_9: 0.8052 - val_loss: 1.2350 - val_acc: 0.8062 - val_mean_squared_error: 5.5016e-05 - val_precision_10: 0.9031 - val_recall_9: 0.7667\n",
            "Epoch 13/15\n",
            "10291/10291 [==============================] - 5s 472us/sample - loss: 0.6554 - acc: 0.8618 - mean_squared_error: 3.9846e-05 - precision_10: 0.9465 - recall_9: 0.8112 - val_loss: 1.2343 - val_acc: 0.8045 - val_mean_squared_error: 5.5602e-05 - val_precision_10: 0.9002 - val_recall_9: 0.7670\n",
            "Epoch 14/15\n",
            "10291/10291 [==============================] - 5s 475us/sample - loss: 0.6067 - acc: 0.8698 - mean_squared_error: 3.8089e-05 - precision_10: 0.9478 - recall_9: 0.8188 - val_loss: 1.2262 - val_acc: 0.8105 - val_mean_squared_error: 5.4644e-05 - val_precision_10: 0.8981 - val_recall_9: 0.7753\n",
            "Epoch 15/15\n",
            "10291/10291 [==============================] - 5s 468us/sample - loss: 0.5621 - acc: 0.8780 - mean_squared_error: 3.6218e-05 - precision_10: 0.9492 - recall_9: 0.8274 - val_loss: 1.2215 - val_acc: 0.8081 - val_mean_squared_error: 5.5002e-05 - val_precision_10: 0.8989 - val_recall_9: 0.7726\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f42a43deef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjapHrel-XV3",
        "outputId": "b3d80165-ac5c-4cab-c55d-c3616693e10d"
      },
      "source": [
        "#embeded_model=tf.keras.models.load_model(\"drive/MyDrive/embedded_15000.h5\")\n",
        "l,acc,mse,p,r=embeded_model.evaluate(te_x,test_y)\n",
        "print(\"Embedded model loss for testing set:{}\".format(l))\n",
        "print(\"Embedded model accuracy for testing set:{}\".format(acc))\n",
        "print(\"Embedded model MSE for testing set:{}\".format(mse))\n",
        "print(\"Embedded model precision for testing set:{}\".format(p))\n",
        "print(\"Embedded model recall for testing set:{}\".format(r))\n",
        "print(\"Embedded model f1_score for testing set:{}\".format((2*p*r)/(p+r)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1485/1485 [==============================] - 1s 427us/sample - loss: 1.1761 - acc: 0.8134 - mean_squared_error: 5.4238e-05 - precision_10: 0.8990 - recall_9: 0.7738\n",
            "Embedded model loss for testing set:1.17609374153895\n",
            "Embedded model accuracy for testing set:0.8134162425994873\n",
            "Embedded model MSE for testing set:5.4237843869486824e-05\n",
            "Embedded model precision for testing set:0.8990190625190735\n",
            "Embedded model recall for testing set:0.7738409638404846\n",
            "Embedded model f1_score for testing set:0.8317465500860717\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS2mEhvO-0kE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "63204c06-181f-4cc8-d16f-e1c77c8f8a10"
      },
      "source": [
        "translate(\"i am so small \",embeded_model,True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ich bin so klein . '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtRyMtkgul-z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvwRH3HrGZkf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPTRowYDGhwJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}